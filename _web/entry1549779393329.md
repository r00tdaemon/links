---
_id: 697353d0-2cfb-11e9-b328-cb733bb1f111
title: Practical Web Cache Poisoning - Blog
link: 'https://portswigger.net/blog/practical-web-cache-poisoning'
excerpt: >-
  In this paper I'll show you how to compromise websites by using esoteric web
  features to turn their caches into exploit delivery systems
category: web
header:
  overlay_image: >-
    https://portswigger.net/cms/images/d0/43/5e5ed09ea718-twittercard-cache-poisoning-article.png
date: '2019-02-10T06:16:33.328Z'
---
<p>
 James Kettle |
09 August 2018 at 23:20 UTC
</p>
<p>
 <p>
  <img src="https://portswigger.net/cms/images/21/ed/0358ad020c37-article-cache-poisoning-article.png"/>
 </p>
</p>
Abstract
<p>
 Web cache poisoning has long been an elusive vulnerability, a 'theoretical' threat used mostly to scare developers into obediently patching issues that nobody could actually exploit.
</p>
<p>
 In this paper I'll show you how to compromise websites by using esoteric web features to turn their caches into exploit delivery systems, targeting everyone that makes the mistake of visiting their homepage.
</p>
<p>
 I'll illustrate and develop this technique with vulnerabilities that handed me control over numerous popular websites and frameworks, progressing from simple single-request attacks to intricate exploit chains that hijack JavaScript, pivot across cache layers, subvert social media and misdirect cloud services. I'll wrap up by discussing defense against cache poisoning, and releasing the open source Burp Suite Community extension that fueled this research.
</p>
<p>
 You can also
 <a href="https://www.youtube.com/watch?v=iSDoUGjfW3Q">
  watch my presentation
 </a>
 on this research, or peruse it as a
 <a href="https://portswigger.net/kb/papers/7q1e9u9a/web-cache-poisoning.pdf">
  printable whitepaper
 </a>
 .
</p>
Core Concepts Caching 101
<p>
 To grasp cache poisoning, we'll need to take a quick look at the fundamentals of caching. Web caches sit between the user and the application server, where they save and serve copies of certain responses. In the diagram below, we can see three users fetching the same resource one after the other:
</p>
<p>
 <img src="https://portswigger.net/cms/images/d8/e5/22a1637dd763-article-cache.svg"/>
</p>
<p>
 Caching is intended to speed up page loads by reducing latency, and also reduce load on the application server. Some companies host their own cache using software like Varnish, and others opt to rely on a Content Delivery Network (CDN) like Cloudflare, with caches scattered across geographical locations. Also, some popular web applications and frameworks like Drupal have a built-in cache.
</p>
<p>
 There are also other types of cache, such as client-side browser caches and DNS caches, but they're not the focus of this research.
</p>
Cache keys
<p>
 The concept of caching might sound clean and simple, but it hides some risky assumptions. Whenever a cache receives a request for a resource, it needs to decide whether it has a copy of this exact resource already saved and can reply with that, or if it needs to forward the request to the application server.
</p>
<p>
 Identifying whether two requests are trying to load the same resource can be tricky; requiring that the requests match byte-for-byte is utterly ineffective, as HTTP requests are full of inconsequential data, such as the requester's browser:
</p>
GET /blog/post.php?mobile=1 HTTP/1.1 Host: example.com User-Agent: Mozilla/5.0 … Firefox/57.0 Accept: */*; q=0.01 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate Referer: https://google.com/ Cookie: jessionid=xyz; Connection: close
<p>
 Caches tackle this problem using the concept of cache keys – a few specific components of a HTTP request that are taken to fully identify the resource being requested. In the request above, I've highlighted the values included in a typical cache key in orange.
</p>
<p>
 This means that caches think the following two requests are equivalent, and will happily respond to the second request with a response cached from the first:
</p>
GET /blog/post.php?mobile=1 HTTP/1.1 Host: example.com User-Agent: Mozilla/5.0 … Firefox/57.0 Cookie: language=pl; Connection: closeGET /blog/post.php?mobile=1 HTTP/1.1 Host: example.com User-Agent: Mozilla/5.0 … Firefox/57.0 Cookie: language=en; Connection: close
<p>
 As a result, the page will be served in the wrong language to the second visitor. This hints at the problem – any difference in the response triggered by an unkeyed input may be stored and served to other users. In theory, sites can use the 'Vary' response header to specify additional request headers that should be keyed. in practice, the Vary header is only used in a rudimentary way, CDNs like Cloudflare ignore it outright, and people don't even realise their application supports any header-based input.
</p>
<p>
 This causes a healthy number of accidental breakages, but the fun really starts when someone intentionally sets out to exploit it.
</p>
Cache Poisoning
<p>
 The objective of web cache poisoning is to send a request that causes a harmful response that gets saved in the cache and served to other users.
</p>
<p>
 <p>
  <img src="https://portswigger.net/cms/images/99/13/6505c296bdf4-article-cachepoisoningattack.svg"/>
 </p>
</p>
<p>
 In this paper, we're going to poison caches using unkeyed inputs like HTTP headers. This isn't the only way of poisoning caches - you can also use HTTP Response Splitting and
 <a href="https://media.defcon.org/DEF%20CON%2024/DEF%20CON%2024%20presentations/DEFCON-24-Regilero-Hiding-Wookiees-In-Http.pdf">
  Request Smuggling
 </a>
 - but I think it's the best. Please note that web caches also enable a different type of attack called
 <a href="https://omergil.blogspot.com/2017/02/web-cache-deception-attack.html">
  Web Cache Deception
 </a>
 which should not be confused with cache poisoning.
</p>
Methodology
<p>
 We'll use the following methodology to find cache poisoning vulnerabilities:
</p>
<p>
 <p>
  <img src="https://portswigger.net/cms/images/ec/b8/0d97faa475af-article-methodology-full-landscape.svg"/>
 </p>
</p>
<p>
 Rather than attempt to explain this in depth upfront, I'll give a quick overview then demonstrate it being applied to real websites.
</p>
<p>
 The first step is to identify unkeyed inputs. Doing this manually is tedious so I've developed an open source Burp Suite extension called
 <a href="https://github.com/PortSwigger/param-miner">
  Param Miner
 </a>
 that automates this step by guessing header/cookie names, and observing whether they have an effect on the application's response.
</p>
<p>
 After finding an unkeyed input, the next steps are to assess how much damage you can do with it, then try and get it stored in the cache. If that fails, you'll need to gain a better understanding of how the cache works and hunt down a cacheable target page before retrying. Whether a page gets cached may be based on a variety of factors including the file extension, content-type, route, status code, and response headers.
</p>
<p>
 Cached responses can mask unkeyed inputs, so if you're trying to manually detect or explore unkeyed inputs, a cache-buster is crucial. If you have Param Miner loaded, you can ensure every request has a unique cache key by adding a parameter with a value of $randomplz to the query string.
</p>
<p>
 When auditing a live website, accidentally poisoning other visitors is a perpetual hazard. Param Miner mitigates this by adding a cache buster to all outbound requests from Burp. This cache buster has a fixed value so you can observe caching behaviour yourself without it affecting other users.
</p>
Case Studies
<p>
 Let's take a look at what happens when the methodology is applied to real websites. As usual, I've exclusively targeted sites with researcher-friendly security policies. All the vulnerabilities discussed here have been reported and patched, although due to 'private' programs I've been forced to redact a few.
</p>
<p>
 The response from my targets was mixed; Unity patched everything swiftly and rewarded well, Mozilla at least patched quickly, and others including data.gov and Ghost did nothing for months and only patched due to the threat of imminent publication.
</p>
<p>
 Many of these case studies exploit secondary vulnerabilities such as
 <a href="https://portswigger.net/web-security/cross-site-scripting">
  XSS
 </a>
 in the unkeyed input, and it's important to remember that without cache poisoning, such vulnerabilities are useless as there's no reliable way to force another user to send a custom header on a cross-domain request. That's probably why they were so easy to find.
</p>
Basic Poisoning
<p>
 In spite of its fearsome reputation, cache poisoning is often very easy to exploit. To get started, let's take a look at Red Hat's homepage. Param Miner immediately spotted an unkeyed input:
</p>
GET /en?cb=1 HTTP/1.1 Host: www.redhat.com X-Forwarded-Host: canary
<p>
 HTTP/1.1 200 OK Cache-Control: public, no-cache … &lt;meta property="og:image" content="https://canary/cms/social.png" /&gt;
</p>
<p>
 Here we can see that the X-Forwarded-Host header has been used by the application to generate an Open Graph URL inside a meta tag. The next step is to explore whether it's exploitable – we'll start with a simple
 <a href="https://portswigger.net/web-security/cross-site-scripting">
  cross-site scripting
 </a>
 payload:
</p>
GET /en?dontpoisoneveryone=1 HTTP/1.1 Host: www.redhat.com X-Forwarded-Host: a."&gt;&lt;script&gt;alert(1)&lt;/script&gt;
<p>
 HTTP/1.1 200 OK Cache-Control: public, no-cache … &lt;meta property="og:image" content="https://a."&gt;&lt;script&gt;alert(1)&lt;/script&gt;"/&gt;
</p>
<p>
 Looks good – we've just confirmed that we can cause a response that will execute arbitrary JavaScript against whoever views it. The final step is to check if this response has been stored in a cache so that it'll be delivered to other users. Don't let the 'Cache Control: no-cache' header dissuade you – it's always better to attempt an attack than assume it won't work. You can verify first by resending the request without the malicious header, and then by fetching the URL directly in a browser on a different machine:
</p>
GET /en?dontpoisoneveryone=1 HTTP/1.1 Host: www.redhat.com
<p>
 HTTP/1.1 200 OK … &lt;meta property="og:image" content="https://a."&gt;&lt;script&gt;alert(1)&lt;/script&gt;"/&gt;
</p>
<p>
 That was easy. Although the response doesn't have any headers that suggest a ca ...
